Emily Schultz (ess2183)
COMS 4705 - Natural Language Processing
September 27, 2013


Homework 1: Programming Problems (Q4-6)

*** I'm using my 5 "free" late days on this problem set. ***

This code was written and runs on a computer using python 2.6.6. I've also tested it on the CLIC machines.


REPORT OF RESULTS

Question 4:


Part1: how to run your code step by step


1. Run in terminal:
	python rare.py ner_train.dat
to replace infrequent words (count(x) < 5) in the original training data file (ner_train.dat) with a common symbol _RARE_. This will produce the file: rare_replaced.dat, which is identical to the training data file: ner_train.dat, except the _RARE_ keyword replaces words with counts < 5.

2. Next run:
	python count_freqs.py rare_replaced.dat > ner_rare.counts
to get an output of counts, using _RARE_ keyword replacement.

3. Next run:
	python p4.py ner_rare.counts ner_dev.dat > prediction_file
to run the simple named entity tagger on the _RARE_ replaced data.

4. To evaluate the predictions of the entity tagger, run:
	python eval_ne_tagger.py ner_dev.key prediction_file


Part2: performance for your algorithm (including precision, recall, and F-score).


After running count_freqs.py on the rare_replaced.dat file, the _RARE_ counts (with tags) are below:
19243 WORDTAG O _RARE_
1466 WORDTAG I-LOC _RARE_
9 WORDTAG B-LOC _RARE_
5462 WORDTAG I-PER _RARE_
10 WORDTAG B-MISC _RARE_
863 WORDTAG I-MISC _RARE_
3207 WORDTAG I-ORG _RARE_

Output from eval_ne_tagger.py:

Found 48511 NEs. Expected 5931 NEs; Correct: 1602.

	 	precision 	recall 		F1-Score
Total:	 0.033023	0.270106	0.058852
PER:	 0.000000	0.000000	0.000000
Warning: prediction file does not contain any instances of entity type ORG.
ORG:	 1.000000	0.000000	0.000000
LOC:	 0.033040	0.873501	0.063672
MISC:	 0.000000	0.000000	0.000000


Part3: observations and comments about your experimental results. 


My simple named entity tagger got 1602 correct. It found 48511 named entities and expected 5931. Overall this is not very impressive. The MISC tag received 0.0 for precision, recall, and F1-Score, as did PER tag. The LOC tag had the best results for all three. Overall, precision was about .03, recall about .27, and F1-Score overall was 0.05.


Part4: any additional information that is requested in the problem.


The function that computes emission parameters is in the Hmm class of count_freqs.py, called e().




Question 5:


Part1: how to run your code step by step (make sure your code can run on CLIC). 

1. Run in terminal:
	python count_freqs.py ner_train.dat > ner.counts
to get the original counts (without the _RARE_ keyword introduced)

2. Run:
	python p5.py tri_prob_in ner.counts > tri_prob_out
to test the trigram q() function (in count_freqs.py Hmm class) on the tri_prob list of state trigrams.

Part2: performance for your algorithm (including precision, recall, and F-score). 


Part3: observations and comments about your experimental results. 


Part4: any additional information that is requested in the problem.




Question 6:
Part1: how to run your code step by step (make sure your code can run on CLIC). 


Part2: performance for your algorithm (including precision, recall, and F-score). 


Part3: observations and comments about your experimental results. 


Part4: any additional information that is requested in the problem.

